# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ipNPK9N9UTOKpAC7jgf1AvTFimdip72q
"""

from google.colab import files
uploaded = files.upload()

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import GRU, Dense, Dropout
from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score
import matplotlib.pyplot as plt
from tensorflow.keras.optimizers import Adam
from sklearn.model_selection import train_test_split
def load_and_preprocess_data(file_path, time_steps=20, frame_step=3, frame_block=100):
    # 엑셀 파일 로드
    data = pd.read_excel(file_path)

    # 필요한 열만 선택 (V, AbsoluteHeight, label)
    selected_data = data[['V', 'AbsoluteHeight']]
    labels = data['label']

    # 입력 데이터를 소수점 3자리까지 반올림
    selected_data = selected_data.round(2)
    # 데이터를 numpy 배열로 변환
    data_values = selected_data.values
    label_values = labels.values

    # 슬라이딩 윈도우 방식으로 데이터 분할
    X = []
    Y = []
    num_blocks = len(data_values) // frame_block

    for block in range(num_blocks):
        start_index = block * frame_block
        end_index = start_index + frame_block
        block_data = data_values[start_index:end_index]
        block_labels = label_values[start_index:end_index]

        for start in range(0, frame_block - time_steps + 1, frame_step):
            end = start + time_steps
            X.append(block_data[start:end])
            Y.append(block_labels[start:end])

    # 마지막 블록이 frame_block 길이보다 짧을 때 처리
    if len(data_values) % frame_block != 0:
        start_index = num_blocks * frame_block
        block_data = data_values[start_index:]
        block_labels = label_values[start_index:]
        for start in range(0, len(block_data) - time_steps + 1, frame_step):
            end = start + time_steps
            X.append(block_data[start:end])
            Y.append(block_labels[start:end])

    X = np.array(X)
    Y = np.array(Y)
    return X, Y

# 학습용 CSV 파일 경로
train_xlsx_file = 'train.xlsx'


# 학습용 데이터 로드 및 전처리
X_train, Y_train = load_and_preprocess_data(train_xlsx_file, time_steps=25, frame_step=1, frame_block=100)
X_train, X_val, Y_train,Y_val = train_test_split(X_train, Y_train,test_size=0.3,random_state=1)

print(X_train.shape)  # 확인용 출력
print(Y_train.shape)  # 확인용 출력
print(X_val.shape)  # 확인용 출력
print(Y_val.shape)  # 확인용 출력

# 모델 정의
model = Sequential()

model.add(GRU(32, reset_after=False, return_sequences=True, input_shape=(25, 2)))
model.add(Dropout(0.2))
model.add(GRU(64, reset_after=False, return_sequences=True))
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])

history = model.fit(X_train, Y_train, epochs=100, batch_size = 16, validation_data=(X_val, Y_val))

plt.plot(history.history['loss'], label='train loss')
plt.plot(history.history['val_loss'], label='validation loss')
plt.plot(history.history['accuracy'], label='train acc')
plt.plot(history.history['val_accuracy'], label='validation acc')

plt.legend()
plt.xlabel('epoch')
plt.ylabel('loss')
plt.show()

model.save('my_model3.h5')

from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score, recall_score, precision_score
# 검증 데이터에 대한 예측
Y_pred_prob = model.predict(X_val)
Y_pred = np.where(Y_pred_prob > 0.35, 1, 0)
print(Y_pred.shape)
print(Y_val.shape)

# 2차원 배열 Y_val을 1차원 배열로 변환
def convert_to_binary(y_val, threshold=2):
    # 새로운 1차원 배열 초기화
    y_converted = []

    # 각 행에 대해 1의 개수를 세고 조건에 따라 값을 결정
    for row in y_val:
        if np.sum(row) >= threshold:
            y_converted.append(1)
        else:
            y_converted.append(0)

    return np.array(y_converted)

# Y_val 변환
Y_val_converted = convert_to_binary(Y_val, threshold=2)

# 결과 출력
print("Original Y_val shape:", Y_val.shape)
print("Converted Y_val shape:", Y_val_converted.shape)
print("Converted Y_val:", Y_val_converted)

# Y_pred 변환
Y_pred_converted = convert_to_binary(Y_pred, threshold=2)

# 결과 출력
print("Original Y_pred shape:", Y_pred.shape)
print("Converted Y_pred shape:", Y_pred_converted.shape)
print("Converted Y_pred:", Y_pred_converted)



# 성능 지표 계산
f1 = f1_score(Y_val_converted, Y_pred_converted)
accuracy = np.mean(Y_val_converted == Y_pred_converted)
recall = recall_score(Y_val_converted, Y_pred_converted)
precision = precision_score(Y_val_converted, Y_pred_converted)

# ROC 곡선 계산
fpr, tpr, _ = roc_curve(Y_val_converted, Y_pred_converted)
roc_auc = auc(fpr, tpr)

# Precision-Recall 곡선 계산
precision_curve, recall_curve, _ = precision_recall_curve(Y_val_converted, Y_pred_converted)

# 결과 시각화
plt.figure(figsize=(15, 5))

# ROC 곡선
plt.subplot(1, 3, 1)
plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic')
plt.legend(loc="lower right")

# Precision-Recall 곡선
plt.subplot(1, 3, 2)
plt.plot(recall_curve, precision_curve, color='blue', lw=2, label='Precision-Recall curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc="lower left")

# F1 Score, Accuracy, Recall 및 Precision
plt.subplot(1, 3, 3)
plt.text(0.5, 0.7, 'F1 Score: %.2f' % f1, fontsize=12, ha='center')
plt.text(0.5, 0.5, 'Accuracy: %.2f' % accuracy, fontsize=12, ha='center')
plt.text(0.5, 0.3, 'Recall: %.2f' % recall, fontsize=12, ha='center')
plt.text(0.5, 0.1, 'Precision: %.2f' % precision, fontsize=12, ha='center')
plt.axis('off')

plt.tight_layout()
plt.show()

# 학습 및 검증 정확도 시각화
plt.figure(figsize=(15, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Training and Validation Accuracy')
plt.legend()
plt.show()

# 학습 및 검증 손실 시각화
plt.figure(figsize=(15, 5))
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()

def compare_values(y_val_converted, y_pred_converted):
    # 비교할 구간 수 결정
    compare_segments = len(y_val_converted)//20

    for i in range(compare_segments):
        print(f"Segment {i + 1}:")
        print(f"Y_val_converted: ",end=" ")
        for j in range(20):
          print(f"{y_val_converted[i*20+j]}",end=" ")
        print()
        print(f"Y_pred_converted:",end=" ")
        for j in range(20):
          print(f"{y_pred_converted[i*20+j]}",end=" ")
        print()

# Y_val_converted와 Y_pred_converted의 값을 20개씩 잘라서 비교
compare_values(Y_val_converted, Y_pred_converted)